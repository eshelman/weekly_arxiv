# SPHINX-X: Scaling Data and Parameters for a Family of Multi-modal Large Language Models

Published: 2024-02-08T18:59:48Z
[Link to the paper](http://arxiv.org/abs/2402.05935v1)

## Authors

- Peng Gao
- Renrui Zhang
- Chris Liu
- Longtian Qiu
- Siyuan Huang
- Weifeng Lin
- Shitian Zhao
- Shijie Geng
- Ziyi Lin
- Peng Jin
- Kaipeng Zhang
- Wenqi Shao
- Chao Xu
- Conghui He
- Junjun He
- Hao Shao
- Pan Lu
- Hongsheng Li
- Yu Qiao
## Summary
  We propose SPHINX-X, an extensive Multimodality Large Language Model (MLLM)
series developed upon SPHINX. To improve the architecture and training
efficiency, we modify the SPHINX framework by removing redundant visual
encoders, bypassing fully-padded sub-images with skip tokens, and simplifying
multi-stage training into a one-stage all-in-one paradigm. To fully unleash the
potential of MLLMs, we assemble a comprehensive multi-domain and multimodal
dataset covering publicly available resources in language, vision, and
vision-language tasks. We further enrich this collection with our curated OCR
intensive and Set-of-Mark datasets, extending the diversity and generality. By
training over different base LLMs including TinyLlama1.1B, InternLM2-7B,
LLaMA2-13B, and Mixtral8x7B, we obtain a spectrum of MLLMs that vary in
parameter size and multilingual capabilities. Comprehensive benchmarking
reveals a strong correlation between the multi-modal performance with the data
and parameter scales. Code and models are released at
https://github.com/Alpha-VLLM/LLaMA2-Accessory



# Driving Everywhere with Large Language Model Policy Adaptation

Published: 2024-02-08T18:59:03Z
[Link to the paper](http://arxiv.org/abs/2402.05932v1)

## Authors

- Boyi Li
- Yue Wang
- Jiageng Mao
- Boris Ivanovic
- Sushant Veer
- Karen Leung
- Marco Pavone
## Summary
  Adapting driving behavior to new environments, customs, and laws is a
long-standing problem in autonomous driving, precluding the widespread
deployment of autonomous vehicles (AVs). In this paper, we present LLaDA, a
simple yet powerful tool that enables human drivers and autonomous vehicles
alike to drive everywhere by adapting their tasks and motion plans to traffic
rules in new locations. LLaDA achieves this by leveraging the impressive
zero-shot generalizability of large language models (LLMs) in interpreting the
traffic rules in the local driver handbook. Through an extensive user study, we
show that LLaDA's instructions are useful in disambiguating in-the-wild
unexpected situations. We also demonstrate LLaDA's ability to adapt AV motion
planning policies in real-world datasets; LLaDA outperforms baseline planning
approaches on all our metrics. Please check our website for more details:
https://boyiliee.github.io/llada.



# WebLINX: Real-World Website Navigation with Multi-Turn Dialogue

Published: 2024-02-08T18:58:02Z
[Link to the paper](http://arxiv.org/abs/2402.05930v1)

## Authors

- Xing Han Lù
- Zdeněk Kasner
- Siva Reddy
## Summary
  We propose the problem of conversational web navigation, where a digital
agent controls a web browser and follows user instructions to solve real-world
tasks in a multi-turn dialogue fashion. To support this problem, we introduce
WEBLINX - a large-scale benchmark of 100K interactions across 2300 expert
demonstrations of conversational web navigation. Our benchmark covers a broad
range of patterns on over 150 real-world websites and can be used to train and
evaluate agents in diverse scenarios. Due to the magnitude of information
present, Large Language Models (LLMs) cannot process entire web pages in
real-time. To solve this bottleneck, we design a retrieval-inspired model that
efficiently prunes HTML pages by ranking relevant elements. We use the selected
elements, along with screenshots and action history, to assess a variety of
models for their ability to replicate human behavior when navigating the web.
Our experiments span from small text-only to proprietary multimodal LLMs. We
find that smaller finetuned decoders surpass the best zero-shot LLMs (including
GPT-4V), but also larger finetuned multimodal models which were explicitly
pretrained on screenshots. However, all finetuned models struggle to generalize
to unseen websites. Our findings highlight the need for large multimodal models
that can generalize to novel settings. Our code, data and models are available
for research: https://mcgill-nlp.github.io/weblinx



# On the Convergence of Zeroth-Order Federated Tuning in Large Language Models

Published: 2024-02-08T18:56:40Z
[Link to the paper](http://arxiv.org/abs/2402.05926v1)

## Authors

- Zhenqing Ling
- Daoyuan Chen
- Liuyi Yao
- Yaliang Li
- Ying Shen
## Summary
  The confluence of Federated Learning (FL) and Large Language Models (LLMs) is
ushering in a new era in privacy-preserving natural language processing.
However, the intensive memory requirements for fine-tuning LLMs pose
significant challenges, especially when deploying on edge devices with limited
computational resources. To circumvent this, we explore the novel integration
of Memory-efficient Zeroth-Order Optimization within a federated setting, a
synergy we denote as FedMeZO. Our study is the first to examine the theoretical
underpinnings of FedMeZO in the context of LLMs, tackling key questions
regarding the influence of large parameter spaces on optimization behavior, the
establishment of convergence properties, and the identification of critical
parameters for convergence to inform personalized federated strategies. Our
extensive empirical evidence supports the theory, showing that FedMeZO not only
converges faster than traditional first-order methods such as SGD but also
significantly reduces GPU memory usage during training to levels comparable to
those during inference. Moreover, the proposed personalized FL strategy that is
built upon the theoretical insights to customize the client-wise learning rate
can effectively accelerate loss reduction. We hope our work can help to bridge
theoretical and practical aspects of federated fine-tuning for LLMs and
facilitate further development and research.



# FACT-GPT: Fact-Checking Augmentation via Claim Matching with LLMs

Published: 2024-02-08T18:43:05Z
[Link to the paper](http://arxiv.org/abs/2402.05904v1)

## Authors

- Eun Cheol Choi
- Emilio Ferrara
## Summary
  Our society is facing rampant misinformation harming public health and trust.
To address the societal challenge, we introduce FACT-GPT, a system leveraging
Large Language Models (LLMs) to automate the claim matching stage of
fact-checking. FACT-GPT, trained on a synthetic dataset, identifies social
media content that aligns with, contradicts, or is irrelevant to previously
debunked claims. Our evaluation shows that our specialized LLMs can match the
accuracy of larger models in identifying related claims, closely mirroring
human judgment. This research provides an automated solution for efficient
claim matching, demonstrates the potential of LLMs in supporting fact-checkers,
and offers valuable resources for further research in the field.



